---
title: God Spiked the Integers
format: 
  html:
    html-math-method: katex
jupyter: julia-1.9
execute:
  cache: true
---

## Binomial Regression

There are 2 "flavors" of Binomial Regression:

1. Logistic Regression: data is organized into single trial cases, each trial is 0 or 1
2. Aggregated Binomial Regression: individual trials with the same covariates are aggregated into a 
number of "successes"

```{julia}
using CSV, DataFrames, DataFramesMeta
using Distributions, Turing, MCMCChains, Plots, StatsPlots, LinearAlgebra, Statistics
using StatsFuns: logistic

c = CSV.read("../data/chimpanzees.csv", DataFrame);
first(c, 10)
```
The idea here is that chimpanzees have 2 options to choose from: to be prosocial or not. There
are some blinders here to control for handedness, but all options can be controlled for. We 
transform the predictor into a index variable for the possible combinations:  

1. 2 items on right lever and no partner
2. 2 items on left lever and no partner
3. 2 items on right lever and a partner
4. 2 items on left lever and a partner

The variable `prosoc_left` contains which lever the 2 food items are on and treatment contains 
whether a partner was in the room. 

```{julia}
c = @transform c :treatment = 1 .+ :prosoc_left + 2 * :condition
```

We are trying to model the probability that the chimp pulled the lever on the left. 

Our model is the following
\begin{align*}
L_i &\sim \mathrm{Binomial}(1, p_i) \\
\mathrm{logit}(p_i) &= \alpha_{\mathrm{Actor}[i]} + \beta_{\mathrm{Treatment}[i]}
\end{align*}

Actor is the id of the chimpanzee. In total, we will have 7 $\alpha$ parameters, one for each
chimpanzee, and 4 $\beta$, one for each treatment. 

We need to determine priors for these, so we'll do prior-predictives with ignoring $\beta$ to get
sensible starting-points for $\alpha$.

```{julia}
@model function binomial_prior_check(l)
  alpha ~ Normal(0, 10)
  for i in eachindex(l)
    v = logistic(alpha)
    l[i] ~ Bernoulli(v)
    end
end

p = binomial_prior_check(c[:, :pulled_left])
chain = sample(p, Prior(), 1000)
```

```{julia}
prior_preds = logistic.(chain[:alpha])
density(prior_preds, trim = true, bandwidth = 0.1)
```

From here, you can notice that there are spikes in probabilities at the extreme edges. So, our prior
on $\alpha$ is too wide. Narrowing that fixes this issue, so we replace 10, with 1.5. 

Now, we investigate the effect of priors for $\beta$. This is slightly tricker as we will need
treatments in this model to index the $\beta$s. 

```{julia}
@model function binomial_prior_check(l, t)
  alpha ~ Normal(0, 1.5)
  beta ~ MvNormal(zeros(4), 10 * I)
  for i in eachindex(l)
    v = logistic(alpha + beta[t[i]])
    l[i] ~ Bernoulli(v)
  end
end

p = binomial_prior_check(c[:, :pulled_left], c[:, :treatment])
chain = sample(p, Prior(), 1000)
```

```{julia}
prior_preds = hcat([logistic.(chain[:alpha] .+ chain["beta[$i]"]) for i in 1:4]...)
prior_diffs12 = abs.(prior_preds[:, 1] - prior_preds[:, 2])
density(prior_diffs12, trim = true)
```

We don't see the large spike at one, but we do see somewhat similar results to the 0.5 prior used.
So, to keep with the book, we will use the 0.5 prior. We can now fully model the actual data.

```{julia}
@model function binomial_chimp(l, t, a)
  alpha ~ MvNormal(zeros(7), 1.5 * I)
  beta ~ MvNormal(zeros(4), 0.5 * I)
  for i in eachindex(l)
    v = logistic(alpha[a[i]] + beta[t[i]])
    l[i] ~ Bernoulli(v)
  end
end

post = binomial_chimp(c[:, :pulled_left], c[:, :treatment], c[:, :actor])
chains = sample(post, HMC(0.05, 10), MCMCThreads(), 1000, 4)
```

```{julia}
plot(chains)
```

Trace plots seem to behave correctly, and all chains seem to have traversed similar regions, so
we can be confident in our posterior samples.

Now, we can just produce something similar for the analysis done on the $\alpha$s and $\beta$s in 
the same vein as the book. 

Each $\alpha$ is for each individual chimpanzee and should reflect each of their proclivity to pull
the left lever without any disincentive.
```{julia}
alphas = @select DataFrame(MCMCChains.group(chains, :alpha)) $(Not(:iteration)) $(Not(:chain))
alphas = stack(alphas);
```

```{julia}
alpha_preds = @transform alphas :prob = logistic.(:value);
```

```{julia}
@df alpha_preds density(:prob, group = :variable, trim = true)
```
Each $beta$ should have the effect of the treatment encoded within. 
```{julia}
betas = @select DataFrame(MCMCChains.group(chains, :beta)) $(Not(:iteration)) $(Not(:chain)) 
betas_stack = stack(betas);
```

This has distribution of $\beta$s inside. 
```{julia}
@df betas_stack density(:value, group = :variable)
```

To get a better sense of the actual impact of having a partner in the room, let's look at 
differences between treatments with prosocial options on the same side for with and without 
partners.

```{julia}
beta_diff = stack(DataFrame((rp = betas[:, 1] - betas[:, 3], lp = betas[:, 2] - betas[:, 4])));
```

```{julia}
@df beta_diff density(:value, group = :variable)
```
There's no clear answer to whether we see a clear indication that chimpanzees are pro-social.

## Poisson Regression

The poisson distribution is useful for modelling count data with no known upper bound (as in the 
Binomial distribution). Theoretically, there are 2 justifications. In the book, he mentions that
the Poisson can be seen as a "special" case of the binomial. (I've never heard of it being a 
special case but a limiting distribution as $n$ approaches $\infty$). It seems like it is a decent
approximation still when $n$ is large and $p$ is small. 

Poisson regression has a simple form, mainly due to the Poisson distribution being characterized by
a single parameter:
\begin{align*}
y_i &\sim \mathrm{Poisson}(\lambda_i) \\
\log(\lambda_i) &= \alpha + \beta (x_i - \bar{x})\\
\end{align*}

Note that $\lambda_i$ will control the expected value and variance of the distribution. Care also
needs to be taken with $\lambda_i$, as the $\lambda$ will end up being the result of an exponential
which may grow unexpectedly large.

```{julia}
k = CSV.read("../data/kline.csv", DataFrame)
k
```

```{julia}
k = @chain k begin
  @rtransform begin
    :lP = log(:population)
    :contact_id = :contact == "high" ? 2 : 1
  end
  @transform :P = (:lP .- mean(:lP)) ./ std(:lP)
end
```

